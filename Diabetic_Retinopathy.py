# -*- coding: utf-8 -*-
"""Diabetic_Retinopathy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CQhnx5boDGuODb29W5Vo9GoRP52Ce1XF

### **Diabetic Retinopathy**
"""

from tensorflow import lite
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import pandas as pd
import random, os
import cv2
import shutil
import keras
import matplotlib.pyplot as plt
from matplotlib.image import imread
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.metrics import categorical_accuracy
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/datasets/archive (2)/train.csv')

diagnosis_binary = {
        0: 'No_DR',
        1: 'DR',
        2: 'DR',
        3: 'DR',
        4: 'DR'}

diagnosis_classes = {
    0: 'No_DR',
    1: 'Mild',
    2: 'Moderate',
    3: 'Severe',
    4: 'Proliferate_DR',
}
df["binary"] = df["diagnosis"].map(diagnosis_binary.get)
df["type"] = df["diagnosis"].map(diagnosis_classes.get)

df.head(10)

df.tail(10)

"""### **Data Visualization**"""

df['type'].value_counts().plot(kind='barh',color='grey')

df['binary'].value_counts().plot(kind='barh',color='green')

"""### **Data preprocessing**"""

from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img
from sklearn.preprocessing import LabelBinarizer
!pip install imutils
from imutils import paths
from sklearn.utils import shuffle

width,height=224,224

imagePaths = list(paths.list_images('/content/drive/MyDrive/datasets/archive (2)/gaussian_filtered_images/gaussian_filtered_images'))

data = []
labels = []

for imagePath in imagePaths:
    label = imagePath.split(os.path.sep)[-2]   
    image = load_img(imagePath, target_size=(width, height))
    image = img_to_array(image)
    data.append(image)
    labels.append(label)

data = np.array(data, dtype="float32")
labels = np.array(labels)

lb = LabelBinarizer()
labels = lb.fit_transform(labels)

data, labels = shuffle(data, labels)

print(data.shape)
print(labels.shape)

"""### **Data normalization**"""

data = data / 255.0

"""### **testing, training and validation of dataset**"""

x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=.2)

print("Train images:",x_train.shape)
print("Test images:",x_test.shape)
print("Train label:",y_train.shape)
print("Test label:",y_test.shape)

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)

print("Train images:",x_train.shape)
print("Test images:",x_val.shape)
print("Train label:",y_train.shape)
print("Test label:",y_val.shape)

"""### **VGG16,VGG19,ResNet50,ResNet101,InceptionV3,MobileNet,EfficientNetB7 model**"""

import tensorflow as tf
from keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout
from tensorflow.keras.models import Sequential
from keras.callbacks import EarlyStopping
from keras.applications.vgg16 import VGG16
from keras import layers
from keras.applications.vgg19 import VGG19
from keras.applications.resnet import ResNet50, ResNet101
from keras.applications.mobilenet import MobileNet
from keras.applications.inception_v3 import InceptionV3
from keras.applications.efficientnet import EfficientNetB7

"""### **Pre-trained model**"""

Vgg16 = VGG16(include_top=False, input_shape= (224,224,3)) 
Vgg16.trainable=False

Vgg19 = VGG19(include_top=False, input_shape= (224,224,3))
Vgg19.trainable=False

resnet50 = ResNet50(include_top=False, input_shape= (224,224,3))
resnet50.trainable=False

resnet101 = ResNet101(include_top=False, input_shape= (224,224,3))
resnet101.trainable=False

mobilenet = MobileNet(include_top=False,input_shape=(224,224,3))
mobilenet.trainable=False

inceptionv3 = InceptionV3(include_top=False, input_shape= (224,224,3))
inceptionv3.trainable=False

efficientnetB7 = EfficientNetB7(include_top=False,input_shape=(224,224,3))
efficientnetB7.trainable=False

"""### **VGG16**"""

model1 = Sequential()
model1.add(Vgg16)
model1.add(Dropout(0.25))
model1.add(Flatten())
model1.add(Dense(64 , activation="relu"))
model1.add(Dropout(0.25))
model1.add(Dense(32 , activation="relu"))
#model.add(Dropout(0.25))
model1.add(Dense(5 , activation="sigmoid"))

model1.compile( optimizer="adam" , loss="binary_crossentropy" , metrics="binary_accuracy" )

model1.summary()

callbacks1 = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]
history1 = model1.fit(x_train , y_train , epochs=10 , batch_size=64,
                    validation_data=(x_val,y_val), verbose=1 , callbacks = callbacks1)

"""### **Model Performance**"""

def plot_curves(history1):

  loss = history1.history["loss"]
  val_loss = history1.history["val_loss"]

  accuracy = history1.history["binary_accuracy"]
  val_accuracy = history1.history["val_binary_accuracy"]

  epochs = range(len(history1.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label = "training_loss")
  plt.plot(epochs, val_loss, label = "val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  #plot accuracy
  plt.figure() 
  plt.plot(epochs, accuracy, label = "training_accuracy")
  plt.plot(epochs, val_accuracy, label = "val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend()

plot_curves(history1)

score1 = model1.evaluate(x_test,y_test)

"""### **Prediction**"""

pred1 = model1.predict(x_test)
pred1 = np.argmax(pred1,axis=1)

"""### **Visual prediction**"""

index =5
predictions=["Mild","Moderate","NO_DR","Proliferate_DR","Severe"] 

img = x_test[index]
RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
RGBImg= cv2.resize(RGBImg,(224,224))

plt.imshow(RGBImg)
print(y_test[index]) # true
print(f"Prediction: {predictions[pred1[index]]}")

"""### **VGG19**"""

model1 = Sequential()
model1.add(Vgg19)
model1.add(Dropout(0.25))
model1.add(Flatten()) 
model1.add(Dense(64 , activation="relu")) 
model1.add(Dropout(0.25))
model1.add(Dense(32 , activation="relu"))
#model.add(Dropout(0.25))
model1.add(Dense(5 , activation="sigmoid"))

model1.compile( optimizer="adam" , loss="binary_crossentropy" , metrics="binary_accuracy")
model1.summary()

callbacks1 = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]
history1 = model1.fit(x_train , y_train , epochs=10 , batch_size=64,
                    validation_data=(x_val,y_val), verbose=1 , callbacks = callbacks1)

def plot_curves(history1):

  loss = history1.history["loss"]
  val_loss = history1.history["val_loss"]

  accuracy = history1.history["binary_accuracy"]
  val_accuracy = history1.history["val_binary_accuracy"]

  epochs = range(len(history1.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label = "training_loss")
  plt.plot(epochs, val_loss, label = "val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  #plot accuracy
  plt.figure() 
  plt.plot(epochs, accuracy, label = "training_accuracy")
  plt.plot(epochs, val_accuracy, label = "val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend()

plot_curves(history1)

score1 = model1.evaluate(x_test,y_test)

pred1 = model1.predict(x_test)
pred1 = np.argmax(pred1,axis=1)

index =5
predictions=["Mild","Moderate","NO_DR","Proliferate_DR","Severe"] 

img = x_test[index]
RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
RGBImg= cv2.resize(RGBImg,(224,224))

plt.imshow(RGBImg)
print(y_test[index]) # true
print(f"Prediction: {predictions[pred1[index]]}")

"""### **ResNet50**"""

model1 = Sequential()
model1.add(ResNet50)
model1.add(Dropout(0.25))
model1.add(Flatten()) 
model1.add(Dense(64 , activation="relu")) 
model1.add(Dropout(0.25))
model1.add(Dense(32 , activation="relu"))
#model.add(Dropout(0.25))
model1.add(Dense(5 , activation="sigmoid"))

model1.compile( optimizer="adam" , loss="binary_crossentropy" , metrics="binary_accuracy")
model1.summary()

callbacks1 = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]
history1 = model1.fit(x_train , y_train , epochs=10 , batch_size=64,
                    validation_data=(x_val,y_val), verbose=1 , callbacks = callbacks1)

def plot_curves(history1):

  loss = history1.history["loss"]
  val_loss = history1.history["val_loss"]

  accuracy = history1.history["binary_accuracy"]
  val_accuracy = history1.history["val_binary_accuracy"]

  epochs = range(len(history1.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label = "training_loss")
  plt.plot(epochs, val_loss, label = "val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  #plot accuracy
  plt.figure() 
  plt.plot(epochs, accuracy, label = "training_accuracy")
  plt.plot(epochs, val_accuracy, label = "val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend()
plot_curves(history1)

score1 = model1.evaluate(x_test,y_test)

pred1 = model1.predict(x_test)
pred1 = np.argmax(pred1,axis=1)

index =5
predictions=["Mild","Moderate","NO_DR","Proliferate_DR","Severe"] 

img = x_test[index]
RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
RGBImg= cv2.resize(RGBImg,(224,224))

plt.imshow(RGBImg)
print(y_test[index]) # true
print(f"Prediction: {predictions[pred1[index]]}")

"""### **ResNet101**"""

model1 = Sequential()
model1.add(ResNet101)
model1.add(Dropout(0.25))
model1.add(Flatten()) 
model1.add(Dense(64 , activation="relu")) 
model1.add(Dropout(0.25))
model1.add(Dense(32 , activation="relu"))
#model.add(Dropout(0.25))
model1.add(Dense(5 , activation="sigmoid"))

model1.compile( optimizer="adam" , loss="binary_crossentropy" , metrics="binary_accuracy")
model1.summary()

callbacks1 = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]
history1 = model1.fit(x_train , y_train , epochs=10 , batch_size=64,
                    validation_data=(x_val,y_val), verbose=1 , callbacks = callbacks1)

def plot_curves(history1):

  loss = history1.history["loss"]
  val_loss = history1.history["val_loss"]

  accuracy = history1.history["binary_accuracy"]
  val_accuracy = history1.history["val_binary_accuracy"]

  epochs = range(len(history1.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label = "training_loss")
  plt.plot(epochs, val_loss, label = "val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  #plot accuracy
  plt.figure() 
  plt.plot(epochs, accuracy, label = "training_accuracy")
  plt.plot(epochs, val_accuracy, label = "val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend()
plot_curves(history1)

score1 = model1.evaluate(x_test,y_test)

pred1 = model1.predict(x_test)
pred1 = np.argmax(pred1,axis=1)

index =5
predictions=["Mild","Moderate","NO_DR","Proliferate_DR","Severe"] 

img = x_test[index]
RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
RGBImg= cv2.resize(RGBImg,(224,224))

plt.imshow(RGBImg)
print(y_test[index]) # true
print(f"Prediction: {predictions[pred1[index]]}")

"""### **InceptionV3**"""

model1 = Sequential()
model1.add(InceptionV3)
model1.add(Dropout(0.25))
model1.add(Flatten()) 
model1.add(Dense(64 , activation="relu")) 
model1.add(Dropout(0.25))
model1.add(Dense(32 , activation="relu"))
#model.add(Dropout(0.25))
model1.add(Dense(5 , activation="sigmoid"))

model1.compile( optimizer="adam" , loss="binary_crossentropy" , metrics="binary_accuracy")
model1.summary()

callbacks1 = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]
history1 = model1.fit(x_train , y_train , epochs=10 , batch_size=64,
                    validation_data=(x_val,y_val), verbose=1 , callbacks = callbacks1)

def plot_curves(history1):

  loss = history1.history["loss"]
  val_loss = history1.history["val_loss"]

  accuracy = history1.history["binary_accuracy"]
  val_accuracy = history1.history["val_binary_accuracy"]

  epochs = range(len(history1.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label = "training_loss")
  plt.plot(epochs, val_loss, label = "val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  #plot accuracy
  plt.figure() 
  plt.plot(epochs, accuracy, label = "training_accuracy")
  plt.plot(epochs, val_accuracy, label = "val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend()
plot_curves(history1)

score1 = model1.evaluate(x_test,y_test)

pred1 = model1.predict(x_test)
pred1 = np.argmax(pred1,axis=1)

index =5
predictions=["Mild","Moderate","NO_DR","Proliferate_DR","Severe"] 

img = x_test[index]
RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
RGBImg= cv2.resize(RGBImg,(224,224))

plt.imshow(RGBImg)
print(y_test[index]) # true
print(f"Prediction: {predictions[pred1[index]]}")

"""### **MobileNet**"""

model1 = Sequential()
model1.add(MobileNet)
model1.add(Dropout(0.25))
model1.add(Flatten()) 
model1.add(Dense(64 , activation="relu")) 
model1.add(Dropout(0.25))
model1.add(Dense(32 , activation="relu"))
#model.add(Dropout(0.25))
model1.add(Dense(5 , activation="sigmoid"))

model1.compile( optimizer="adam" , loss="binary_crossentropy" , metrics="binary_accuracy")
model1.summary()

callbacks1 = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]
history1 = model1.fit(x_train , y_train , epochs=10 , batch_size=64,
                    validation_data=(x_val,y_val), verbose=1 , callbacks = callbacks1)

def plot_curves(history1):

  loss = history1.history["loss"]
  val_loss = history1.history["val_loss"]

  accuracy = history1.history["binary_accuracy"]
  val_accuracy = history1.history["val_binary_accuracy"]

  epochs = range(len(history1.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label = "training_loss")
  plt.plot(epochs, val_loss, label = "val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  #plot accuracy
  plt.figure() 
  plt.plot(epochs, accuracy, label = "training_accuracy")
  plt.plot(epochs, val_accuracy, label = "val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend()
plot_curves(history1)

score1 = model1.evaluate(x_test,y_test)

pred1 = model1.predict(x_test)
pred1 = np.argmax(pred1,axis=1)

index =5
predictions=["Mild","Moderate","NO_DR","Proliferate_DR","Severe"] 

img = x_test[index]
RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
RGBImg= cv2.resize(RGBImg,(224,224))

plt.imshow(RGBImg)
print(y_test[index]) # true
print(f"Prediction: {predictions[pred1[index]]}")

"""### **EfficientNetB7**"""

model1 = Sequential()
model1.add(EfficientNetB7)
model1.add(Dropout(0.25))
model1.add(Flatten()) 
model1.add(Dense(64 , activation="relu")) 
model1.add(Dropout(0.25))
model1.add(Dense(32 , activation="relu"))
#model.add(Dropout(0.25))
model1.add(Dense(5 , activation="sigmoid"))

model1.compile( optimizer="adam" , loss="binary_crossentropy" , metrics="binary_accuracy")
model1.summary()

callbacks1 = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]
history1 = model1.fit(x_train , y_train , epochs=10 , batch_size=64,
                    validation_data=(x_val,y_val), verbose=1 , callbacks = callbacks1)

def plot_curves(history1):

  loss = history1.history["loss"]
  val_loss = history1.history["val_loss"]

  accuracy = history1.history["binary_accuracy"]
  val_accuracy = history1.history["val_binary_accuracy"]

  epochs = range(len(history1.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label = "training_loss")
  plt.plot(epochs, val_loss, label = "val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  #plot accuracy
  plt.figure() 
  plt.plot(epochs, accuracy, label = "training_accuracy")
  plt.plot(epochs, val_accuracy, label = "val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend()
plot_curves(history1)

score1 = model1.evaluate(x_test,y_test)

pred1 = model1.predict(x_test)
pred1 = np.argmax(pred1,axis=1)

index =5
predictions=["Mild","Moderate","NO_DR","Proliferate_DR","Severe"] 

img = x_test[index]
RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
RGBImg= cv2.resize(RGBImg,(224,224))

plt.imshow(RGBImg)
print(y_test[index]) # true
print(f"Prediction: {predictions[pred1[index]]}")